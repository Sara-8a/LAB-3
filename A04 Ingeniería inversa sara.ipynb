{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9dc734-cdfa-45b7-8a34-8b9c0606486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush'\n",
      " 'Gerhard Schroeder' 'Hugo Chavez' 'Junichiro Koizumi' 'Tony Blair']\n",
      "(1348, 62, 47)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "print(faces.target_names)\n",
    "print(faces.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd002044",
   "metadata": {},
   "source": [
    "- **¿Qué hace esta celda?**\n",
    "\n",
    "La celda descarga y carga el conjunto Labeled Faces in the Wild (LFW), ampliamente utilizado en aprendizaje automático para tareas de reconocimiento facial; a continuación muestra por pantalla los nombres de las personas presentes en el dataset y las dimensiones del conjunto de imágenes.\n",
    "\n",
    "- **Explicación paso a paso**\n",
    "\n",
    "fetch_lfw_people obtiene el dataset LFW, que contiene fotografías de rostros para trabajos de reconocimiento facial.\n",
    "\n",
    "min_faces_per_person=60 aplica un filtro que conserva únicamente a las personas que cuentan con 60 o más imágenes, evitando así clases con pocas muestras.\n",
    "\n",
    "faces.target_names devuelve la lista de nombres (las clases) incluidas en el conjunto.\n",
    "\n",
    "faces.images.shape da la forma del arreglo de imágenes; por ejemplo, (1348, 62, 47) significa 1,348 imágenes de tamaño 62×47 píxeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f26e2a-361b-4864-89ae-cee0f9c66b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(3, 5)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[],\n",
    "            xlabel=faces.target_names[faces.target[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c3da0",
   "metadata": {},
   "source": [
    "- **¿Qué hace esta celda?**\n",
    "\n",
    "La celda dibuja una cuadrícula de subgráficos para inspeccionar visualmente imágenes del dataset LFW: muestra las primeras 15 caras con sus etiquetas para comprobar la carga de datos, apreciar la variabilidad entre clases y evaluar la calidad de las imágenes antes de entrenar modelos.\n",
    "\n",
    "- **Explicación paso a paso**\n",
    "\n",
    "Se importa matplotlib.pyplot y se activa %matplotlib inline para visualizar dentro del notebook; plt.subplots(3, 5) crea una rejilla de 3×5 ejes; en el bucle for se representan las primeras 15 imágenes faces.images[i] en escala de grises (cmap='bone'), se ocultan las marcas de los ejes (xticks=[], yticks=[]) y se coloca el nombre de la persona como título o etiqueta bajo cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b525bd62-455d-4fd1-a4d0-1c8b77ec381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA as RandomizedPCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pca = RandomizedPCA(n_components=150, whiten=True, random_state=42)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "model = make_pipeline(pca, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53cfb35",
   "metadata": {},
   "source": [
    "- **¿Qué hace esta celda?**\n",
    "\n",
    "La celda crea un modelo de reconocimiento facial que combina reducción de dimensionalidad (PCA) con un clasificador SVM: primero transforma las imágenes en un espacio de 150 componentes principales (eigenfaces) para compactar la información y luego entrena una SVM con núcleo radial sobre esas componentes, lo que reduce ruido y mejora la eficacia y velocidad del clasificador.\n",
    "\n",
    "- **Explicación paso a paso**\n",
    "\n",
    "PCA(n_components=150) proyecta las imágenes en 150 componentes principales, reteniendo la mayor parte de la varianza y reduciendo la dimensionalidad de miles de píxeles a 150 características.\n",
    "\n",
    "whiten=True escala las componentes para que tengan varianza unitaria (descorrelaciona y normaliza), lo que suele ayudar a estabilidad y rendimiento del clasificador.\n",
    "\n",
    "SVC(kernel='rbf') define un clasificador SVM con kernel radial (RBF), capaz de separar clases que no son linealmente separables.\n",
    "\n",
    "class_weight='balanced' ajusta automáticamente los pesos de cada clase en la función de pérdida según su frecuencia, mitigando el impacto de clases desbalanceadas.\n",
    "\n",
    "make_pipeline(pca, svc) encadena PCA y SVM en un pipeline único que aplica la reducción de dimensión y, acto seguido, el entrenamiento/predicción con la SVM, facilitando validación cruzada y uso reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb810b05-f879-4679-a41c-26f555ae7516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(faces.data, faces.target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f9e9c6",
   "metadata": {},
   "source": [
    "- **¿Qué hace esta celda?**\n",
    "\n",
    "La celda divide el conjunto de imágenes y sus etiquetas en dos subconjuntos: uno para entrenar el modelo y otro para evaluar su rendimiento en datos no vistos, de modo que podamos medir la capacidad de generalización del clasificador.\n",
    "\n",
    "- **Explicación paso a paso**\n",
    "\n",
    "Se usa train_test_split para separar faces.data (las imágenes aplanadas) y faces.target (las etiquetas) en conjuntos de entrenamiento y prueba; por defecto la función reserva el 75% de los datos para entrenamiento y el 25% para prueba; random_state=42 fija la semilla del generador aleatorio para que la partición sea reproducible en ejecuciones posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae8acf4-0feb-4081-b566-38f7b30939fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 55.1 s\n",
      "Wall time: 43.4 s\n",
      "{'svc__C': 5, 'svc__gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model, param_grid)\n",
    "\n",
    "%time grid.fit(Xtrain, ytrain)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50237675",
   "metadata": {},
   "source": [
    "- **¿Qué hace esta celda?**\n",
    "\n",
    "La celda realiza una búsqueda exhaustiva de hiperparámetros para el clasificador SVM dentro del pipeline, con el fin de encontrar los valores de C y gamma que maximicen la precisión mediante validación cruzada.\n",
    "\n",
    "- **Explicación paso a paso**\n",
    "\n",
    "Se define param_grid con las combinaciones de hiperparámetros a probar: C, que regula la penalización por errores (regularización), y gamma, que determina la influencia de cada punto en el kernel RBF; los prefijos svc__ indican que estos parámetros corresponden al SVM dentro del pipeline. Luego, GridSearchCV evalúa todas las combinaciones usando validación cruzada para identificar la mejor configuración, que se consulta con grid.best_params_. Finalmente, %time muestra cuánto tarda en completarse todo el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb9e960-fd19-4f29-9073-6805b9a66b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "yfit = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb06db41",
   "metadata": {},
   "source": [
    "- **¿Qué hace esta celda?**\n",
    "\n",
    "La celda utiliza el mejor modelo obtenido de GridSearchCV para realizar predicciones sobre los datos de prueba, permitiendo evaluar el rendimiento final del clasificador con los hiperparámetros óptimos.\n",
    "\n",
    "- **Explicación paso a paso**\n",
    "\n",
    "grid.best_estimator_ recupera el modelo con la mejor combinación de C y gamma encontrada en la búsqueda; luego, model.predict(Xtest) aplica este modelo optimizado para predecir las etiquetas de las imágenes de prueba; finalmente, yfit almacena las clases predichas para cada rostro en Xtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5196d051-d218-48f7-9ae3-95628cb2032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 6)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(Xtest[i].reshape(62, 47), cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.set_ylabel(faces.target_names[yfit[i]].split()[-1],\n",
    "                   color='black' if yfit[i] == ytest[i] else 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0147a988",
   "metadata": {},
   "source": [
    "- **¿Qué hace esta celda?**\n",
    "\n",
    "La celda visualiza una muestra de imágenes de prueba junto con sus predicciones, mostrando en negro las etiquetas correctas y en rojo las incorrectas, para evaluar de manera rápida y visual el desempeño del modelo.\n",
    "\n",
    "- **Explicación paso a paso**\n",
    "\n",
    "Se crea una cuadrícula de 4×6 subgráficos (plt.subplots(4, 6)) para mostrar 24 imágenes; cada imagen de Xtest se reconvierte a su tamaño original (62×47 píxeles) y se dibuja con su etiqueta predicha (yfit[i]); si la predicción coincide con la etiqueta real (ytest[i]), el texto aparece en negro, y si no coincide, en rojo, permitiendo identificar de un vistazo los aciertos y errores del clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71e4113c-3406-4105-bfec-188fca82ddd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     Ariel Sharon       0.65      0.87      0.74        15\n",
      "     Colin Powell       0.83      0.88      0.86        68\n",
      "  Donald Rumsfeld       0.70      0.84      0.76        31\n",
      "    George W Bush       0.97      0.80      0.88       126\n",
      "Gerhard Schroeder       0.76      0.83      0.79        23\n",
      "      Hugo Chavez       0.93      0.70      0.80        20\n",
      "Junichiro Koizumi       0.86      1.00      0.92        12\n",
      "       Tony Blair       0.82      0.98      0.89        42\n",
      "\n",
      "         accuracy                           0.85       337\n",
      "        macro avg       0.82      0.86      0.83       337\n",
      "     weighted avg       0.86      0.85      0.85       337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, yfit,\n",
    "                            target_names=faces.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a8de8e",
   "metadata": {},
   "source": [
    "- **¿Qué hace esta celda?**\n",
    "\n",
    "La celda genera un informe de clasificación que resume el desempeño del modelo usando métricas clave como precisión, exhaustividad y F1-score, permitiendo evaluar qué tan bien el clasificador identifica cada rostro.\n",
    "\n",
    "- **Explicación paso a paso**\n",
    "\n",
    "Se utiliza classification_report para comparar las etiquetas reales (ytest) con las predichas (yfit) y calcular métricas por clase: precisión (proporción de predicciones correctas sobre las positivas), exhaustividad/recall (capacidad del modelo para encontrar todas las instancias reales) y F1-score (media armónica entre precisión y recall). El parámetro target_names asocia estas métricas con los nombres reales de cada persona en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e567f88c-569e-42f3-a186-57477fca0e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(ytest, yfit)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=faces.target_names,\n",
    "            yticklabels=faces.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da4003",
   "metadata": {},
   "source": [
    "- **¿Qué hace esta celda?**\n",
    "\n",
    "La celda visualiza una matriz de confusión, mostrando de forma gráfica cómo clasifica el modelo cada rostro y permitiendo identificar fácilmente las clases donde comete errores.\n",
    "\n",
    "- **Explicación paso a paso**\n",
    "\n",
    "confusion_matrix(ytest, yfit) crea una tabla donde las filas representan las clases reales y las columnas las predicciones; luego, sns.heatmap dibuja esta matriz como un mapa de calor, con los números de aciertos y errores (annot=True), y las etiquetas de los ejes (xticklabels y yticklabels) corresponden a los nombres de las personas. Los valores altos en la diagonal indican que el modelo clasificó correctamente, mientras que los valores fuera de la diagonal muestran confusiones entre clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f58115d-173e-4fd2-8909-1f99d667423c",
   "metadata": {},
   "source": [
    "## **Dataset load_digits**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7f372-e0e9-4ad5-ba81-d6fff4fdd362",
   "metadata": {},
   "source": [
    "### \n",
    "Cargamos el conjunto **Digits** y mostramos los nombres de clase y la forma de las imágenes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2697f7b5-a8d3-41ab-bdfa-96220973139b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(getattr(digits, \"target_names\", list(range(10))))\n",
    "print(digits.images.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc44abd-57f8-4fbb-908d-bf9083530a27",
   "metadata": {},
   "source": [
    "### Visualización de ejemplos del dataset\n",
    "Mostramos una cuadrícula de imágenes para inspección visual rápida (mismas convenciones que antes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "839a95d0-27b5-4f32-886b-aa05da8989f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(3, 5)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(digits.images[i], cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[],\n",
    "            xlabel=str(digits.target[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e469eabb-78ef-45de-ad51-e89ff3b64379",
   "metadata": {},
   "source": [
    "### Creación del modelo con PCA y SVM\n",
    "Construimos el **pipeline** con PCA (blanqueado) + SVC (RBF), igual que antes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fc3a4c5-c9c4-4baf-a122-7465bdf62552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA as RandomizedPCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pca = RandomizedPCA(n_components=40, whiten=True, random_state=42)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "model = make_pipeline(pca, svc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4abc0d3-37ac-4276-94df-b21cd9e51867",
   "metadata": {},
   "source": [
    "### División del conjunto de datos\n",
    "Separación en **entrenamiento** y **prueba** con semilla fija (por defecto 75/25).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7b70125-4171-41da-87fd-3ae7d79d1993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(digits.data, digits.target, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e069e-e895-4dcf-b1b2-4118c86b1450",
   "metadata": {},
   "source": [
    "### Búsqueda de hiperparámetros con GridSearchCV\n",
    "Optimizamos `C` y `gamma` del SVC dentro del mismo pipeline (mismo grid y prefijos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39cb970b-bfb1-4f81-8e11-e9c133fcf1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 28.3 s\n",
      "Wall time: 27.6 s\n",
      "{'svc__C': 5, 'svc__gamma': 0.005}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'svc__C': [1, 5, 10, 50],\n",
    "              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model, param_grid)\n",
    "\n",
    "%time grid.fit(Xtrain, ytrain)\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a29440b-5ac6-4cd1-a876-6bcf89795b62",
   "metadata": {},
   "source": [
    "### Predicción con el mejor modelo\n",
    "Usamos el mejor estimador hallado por la búsqueda para predecir en el set de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e8695ea-e835-43fb-9c1a-b7a0971cc951",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid.best_estimator_\n",
    "yfit = model.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3a7650-9330-4245-a1e2-c57aeb49bffa",
   "metadata": {},
   "source": [
    "### Visualización de predicciones del modelo\n",
    "Mostramos una cuadrícula de imágenes de prueba con la **predicción**; negro si acierta y rojo si falla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e7ae701-d223-4b11-a05e-c4dde45a7521",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 6)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(Xtest[i].reshape(8, 8), cmap='bone')\n",
    "    axi.set(xticks=[], yticks=[])\n",
    "    axi.set_ylabel(str(yfit[i]),\n",
    "                   color='black' if yfit[i] == ytest[i] else 'red')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1587d49f-0d2f-4cb8-8ff6-8e3657f7a052",
   "metadata": {},
   "source": [
    "### Evaluación con classification_report\n",
    "Informe con **precision**, **recall** y **f1-score** por clase y promedios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58457120-97d6-435a-a92c-0beac7ae1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       1.00      1.00      1.00        37\n",
      "           2       1.00      1.00      1.00        38\n",
      "           3       1.00      0.96      0.98        46\n",
      "           4       1.00      1.00      1.00        55\n",
      "           5       0.97      1.00      0.98        59\n",
      "           6       1.00      0.98      0.99        45\n",
      "           7       1.00      0.98      0.99        41\n",
      "           8       0.95      1.00      0.97        38\n",
      "           9       0.98      0.98      0.98        48\n",
      "\n",
      "    accuracy                           0.99       450\n",
      "   macro avg       0.99      0.99      0.99       450\n",
      "weighted avg       0.99      0.99      0.99       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ytest, yfit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936aaa51-0606-4dd4-b32d-91f8b8db5229",
   "metadata": {},
   "source": [
    "### Matriz de confusión\n",
    "Mapa de calor para ver aciertos (diagonal) y confusiones entre dígitos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8129ab2d-6cb8-4e34-b604-5e252b3d87c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(ytest, yfit)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=getattr(digits, \"target_names\", list(range(10))),\n",
    "            yticklabels=getattr(digits, \"target_names\", list(range(10))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
