{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70086771-ad90-497d-9b51-22626c9cce63",
   "metadata": {},
   "source": [
    "# Laboratorio de regresión - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f666e0e-9e63-49f4-96e1-053c5b1738c3",
   "metadata": {},
   "source": [
    "|                |   |\r\n",
    ":----------------|---|\r\n",
    "| **Nombre**     |Sara Hernandez Ochoa   |\r\n",
    "| **Fecha**      15/09/2025|   |\r\n",
    "| **Expediente**750733 |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f352dc-5863-4685-af3c-25f8fcf60841",
   "metadata": {},
   "source": [
    "## Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73fccec-9651-4f74-9d56-a3c2b2097e19",
   "metadata": {},
   "source": [
    "Hemos estado usando `train_test_split` en nuestros modelos anteriores.\n",
    "\n",
    "¿Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe97ab-a033-4d0f-ab73-0cdabe591655",
   "metadata": {},
   "source": [
    "Para dividir los datos en dos conjuntos, uno de entrenamiento y otro de prueba. Para que el modelo aprenda con una parte de los datos y luego se evalúe con información que no ha visto antes. Asi se verifica si el modelo generaliza bien y no solo memoriza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60a028-ed60-4a5c-9308-dee4862e2bac",
   "metadata": {},
   "source": [
    "Si la muestra es un subset de la población y queremos generalizar sobre la población, ¿no sería mejor utilizar todos los datos al entrenar un modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50989a32-59e7-4bef-9b60-89f543d8ca81",
   "metadata": {},
   "source": [
    "Aunque usar todos los datos parece mejor, si no se reserva un conjunto para prueba no se puede saber si el modelo generaliza. Simula información nueva y estimar el error real. Por eso se combina entrenamiento con evaluación, o se usa validación cruzada para aprovechar mejor la muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d96f3-7370-4161-aa67-75f10e5817cd",
   "metadata": {},
   "source": [
    "El propósito de volver a muestrear dentro de nuestro dataset es tener una idea de qué tan buena podría ser la generalización de nuestro modelo. Imagina un dataset ya separado en dos mitades. Utilizas la primera mitad para entrenar el modelo y pruebas en la segunda mitad; la segunda mitad eran datos invisibles para el modelo al momento de entrenar. Esto nos lleva a tres escenario típicos:\n",
    "\n",
    "1. Si el modelo hace buenas predicciones en la segunda mitad, significa que la primera mitad era \"suficiente\" para generalizar.\n",
    "2. Si el modelo no hace buenas predicciones en la segunda mitad, pero sí en la primera mitad, podría ser que había información importante en la segunda mitad que debió haber sido tomada en cuenta al entrenar, o un problema de overfitting.\n",
    "3. Si el modelo no hace buenas predicciones en la segunda mitad, y tampoco en la primera mitad, se tendrían que revisar los factores y/o el modelo seleccionado.\n",
    "\n",
    "El caso ideal sería el 1, pero por estadística los errores y varianzas tienen como entrada el número de muestas, por lo que tenemos menos seguridad de nuestros resutados al usar menos muestras. Si vemos que el modelo generaliza bien podemos unir de nuevo el dataset y entrenar sobre el dataset completo.\n",
    "\n",
    "En el caso 2 está el problema de que no podemos saber qué información es necesaria para el entrenamiento apropiado del modelo; esto nos lleva a pensar que debemos usar el dataset completo para entrenar, pero esto nos lleva al mismo problema de no saber si el modelo puede generalizar.\n",
    "\n",
    "El problema sólo incrementa si se tienen hiperparámetros en el modelo (e.g. $\\lambda$ en regularización)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16176ad-41fc-4f3c-b865-2eb4219152e2",
   "metadata": {},
   "source": [
    "## Leave-One-Out Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7165d-5b5d-4e92-ae7f-7edb12eea745",
   "metadata": {},
   "source": [
    "Este método de validación es una colección de $n$ `train-test-split`. Teniendo un dataset de $n$ muestras, la lógica es:\n",
    "1. Saca una muestra del dataset.\n",
    "2. Entrena tu modelo con las $n-1$ muestras.\n",
    "3. Evalúa tu modelo en la muestra que quedó fuera con el métrico que más se ajuste a la aplicación.\n",
    "4. Regresa la muestra al dataset.\n",
    "5. Repite 1-4 con muestras diferentes hasta haber hecho el procedimiento $n$ veces para $n$ muestras.\n",
    "6. Calcula la media y desviación estándar de los métricos guardados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21340b80-8fa4-4cdf-8fe4-85e4a35febcd",
   "metadata": {},
   "source": [
    "Con los resultados del proceso de validación podemos saber qué tan bueno podría ser el modelo seleccionado con los datos (con/sin transformaciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0983bf1c-a6a2-42e4-a522-92bba6b450ab",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5f076-bc52-482c-9560-ecd0c125efa7",
   "metadata": {},
   "source": [
    "Utiliza el dataset `Motor Trend Car Road Tests`. Elimina la columna `model` y entrena 32 modelos diferentes utilizando Leave-One-Out Cross Validation con target `mpg`. Utiliza MSE como métrico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d1fa61-455c-46be-a75c-7c54a99149e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecb729d9-0f18-4a35-bf68-22baf4a2f83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"Motor Trend Car Road Tests.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fa22214-b837-4580-926a-0c2eb8db919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22deb299-78a1-4a9f-aadb-a37eab4ec725",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # Separar test y train\n",
    "    data_test = data.iloc[[i]]        \n",
    "    data_train = data.drop(i)         \n",
    "    \n",
    "    X_train = data_train.drop(columns=['mpg'])\n",
    "    y_train = data_train['mpg']\n",
    "\n",
    "    X_test = data_test.drop(columns=['mpg'])\n",
    "    y_test = data_test['mpg']\n",
    "\n",
    "    # Entrenar LinearRegression\n",
    "    lr = LinearRegression()\n",
    "    reg = lr.fit(X_train, y_train)\n",
    "\n",
    "    # Predecir y calcular MSE\n",
    "    y_pred_test = reg.predict(X_test)\n",
    "    error = mean_squared_error(y_test, y_pred_test)\n",
    "    mse.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1812c4f1-25b2-4796-b044-b425d30b2f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE promedio: 12.181558006901954\n",
      "Desviación estándar del MSE: 17.340495610343044\n",
      "Intervalo de confianza 95%: (5.929642648176542, 18.433473365627364)\n"
     ]
    }
   ],
   "source": [
    "media = np.mean(mse)                    # MSE promedio\n",
    "desv = np.std(mse, ddof=1)              # Desviación estándar muestral\n",
    "n = len(mse)\n",
    "alpha = 0.05\n",
    "t_crit = st.t.ppf(1 - alpha/2, df=n-1)  # t crítico\n",
    "\n",
    "# Margen de error e intervalo de confianza\n",
    "margen_error = t_crit * (desv / np.sqrt(n))\n",
    "IC = (media - margen_error, media + margen_error)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"MSE promedio:\", media)\n",
    "print(\"Desviación estándar del MSE:\", desv)\n",
    "print(\"Intervalo de confianza 95%:\", IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8724bdb-e50b-4470-b53a-2d9843fae6ea",
   "metadata": {},
   "source": [
    "Interpreta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19904df-1fe6-433a-b1bd-a7ce86ce0eef",
   "metadata": {},
   "source": [
    "El MSE promedio es 12.18, lo que indica que, en promedio, las predicciones del modelo difieren de los valores reales en un error cuadrático de aproximadamente 12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ee166-b442-49f8-bf40-db9aaf9c3db8",
   "metadata": {},
   "source": [
    "La desviación estándar del MSE es 17.34, lo que muestra que los errores individuales varían bastante entre las diferentes iteraciones de LOOCV; algunas predicciones son mucho mejores o peores que otras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234de10e-ab26-4b2b-86f5-b28274dd6886",
   "metadata": {},
   "source": [
    "El intervalo de confianza del 95% va de 5.93 a 18.43, lo que significa que podemos estar razonablemente seguros de que el MSE “real” del modelo (si lo aplicáramos a datos similares) se encuentra dentro de ese rango."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc61dd1-fa5f-43b0-969a-592f8e9fc56f",
   "metadata": {},
   "source": [
    "## K-Folds Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbca526-2c69-4c70-b6b4-270fc51d825b",
   "metadata": {},
   "source": [
    "El dataset `Motor Trend Car Road Tests` sólo tiene 32 muestras, y utilizar un modelo sencillo de regresión múltiple hace que usar LOOCV sea muy rápido. El dataset `California Housing` tiene $20640$ muestras para $9$ columnas, entonces realizar un ajuste sobre una transformación o sobre el modelo y luego calcular el impacto esperado podría tomar más tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a437812-c00e-400f-ae7d-110b3afa5dc3",
   "metadata": {},
   "source": [
    "La solución propuesta es dividir el dataset en *k* folds (partes iguales), ajustar en *k-1* folds y probar en el restante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb82cc3-0d35-442a-a12b-f9c6fd131af2",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "Utiliza el dataset `California Housing` y haz K-folds Cross Validation con 10 folds. Utiliza el MSE como métrico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50e361-edcd-4cdb-9609-68f20d6fca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(\"Dataset Shape:\", housing.data.shape, housing.target.shape)\n",
    "print(\"Dataset Features:\", housing.feature_names)\n",
    "print(\"Dataset Target:\", housing.target_names)\n",
    "X = housing.data\n",
    "y = housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e8570a4-76bb-4d81-a90b-43647b0df438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (20640, 8) (20640,)\n",
      "Dataset Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "MSE por fold: [0.5117242819193435, 0.5073036455116077, 0.4841587761712365, 0.5241268400393478, 0.5330791923450088, 0.5217856372536162, 0.5217818134767094, 0.5606195714023077, 0.5178668381533028, 0.5863146794895464]\n",
      "MSE promedio: 0.5269\n",
      "Desviación estándar del MSE: 0.0285\n",
      "Intervalo de confianza 95%: (0.5065194180131435, 0.547232837139262)\n"
     ]
    }
   ],
   "source": [
    "# Ejercicio 2: K-Fold Cross Validation con California Housing\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Cargar dataset\n",
    "housing = fetch_california_housing()\n",
    "print(\"Dataset Shape:\", housing.data.shape, housing.target.shape)\n",
    "print(\"Dataset Features:\", housing.feature_names)\n",
    "\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "# Definir K-Folds\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=100)\n",
    "\n",
    "mse_scores = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_test)\n",
    "    error = mean_squared_error(y_test, y_pred)\n",
    "    mse_scores.append(error)\n",
    "\n",
    "# Calcular estadísticas\n",
    "media = np.mean(mse_scores)\n",
    "desv = np.std(mse_scores, ddof=1)\n",
    "n = len(mse_scores)\n",
    "alpha = 0.05\n",
    "t_crit = st.t.ppf(1 - alpha/2, df=n-1)\n",
    "\n",
    "margen_error = t_crit * (desv / np.sqrt(n))\n",
    "IC = (media - margen_error, media + margen_error)\n",
    "\n",
    "# Resultados\n",
    "print(\"MSE por fold:\", mse_scores)\n",
    "print(f\"MSE promedio: {media:.4f}\")\n",
    "print(f\"Desviación estándar del MSE: {desv:.4f}\")\n",
    "print(\"Intervalo de confianza 95%:\", IC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7098f-a1de-4508-b3ff-af1484561856",
   "metadata": {},
   "source": [
    "Interpreta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fbaf4d-f62b-46d9-9a35-23fcdd50a8ca",
   "metadata": {},
   "source": [
    "El modelo de regresión lineal aplicado al dataset de California Housing mostró errores (MSE) en cada fold que van de 0.48 a 0.59, con un promedio de 0.527. Esto significa que, en general, el modelo predice con un error cercano a ese valor. La desviación estándar de 0.029 indica que los resultados son consistentes entre los diferentes folds, y el intervalo de confianza al 95% (0.507 – 0.547) confirma que el error esperado del modelo se encuentra con alta probabilidad dentro de ese rango."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5792ac-6d38-4f02-bf10-aeaa0a040d17",
   "metadata": {},
   "source": [
    "## Referencia\n",
    "\n",
    "James, G., Witten, D., Hastie, T., Tibshirani, R.,, Taylor, J. (2023). An Introduction to Statistical Learning with Applications in Python. Cham: Springer. ISBN: 978-3-031-38746-3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
