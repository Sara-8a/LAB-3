{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e2753e4-9dc7-41d7-b080-d1abfbb16b28",
   "metadata": {},
   "source": [
    "# Laboratorio de regresión - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396ea70-b88c-4346-a14f-4aa7ca2e1b00",
   "metadata": {},
   "source": [
    "|                |   |\r\n",
    ":----------------|---|\r\n",
    "| **Nombre**     Sara Hernandez Ochoa|   |\r\n",
    "| **Fecha**     11/09/2025|   |\r\n",
    "| **Expediente**750733 |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77def53e-10bf-474e-acdf-728e07bef102",
   "metadata": {},
   "source": [
    "## Modelos penalizados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb791d-1843-4b4d-bd8b-69e6419511e8",
   "metadata": {},
   "source": [
    "Hasta ahora la función de costo que usamos para decidir qué tan bueno es nuestro modelo al momento de ajustar es:\n",
    "\n",
    "$$ \\text{RSS} = \\sum_{i=1}^n e_i^2 = \\sum_{i=1}^n (y_i - \\hat{y_i})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b5e6b-abe9-4b75-b045-e4444de4fc35",
   "metadata": {},
   "source": [
    "Dado que los errores obtenidos son una combinación de sesgo y varianza, puede ser que se sesgue un parámetro para minimizar el error. Esto significa que el modelo puede decidir que la salida no sea una combinación de los factores, sino una fuerte predilección sobre uno de los factores solamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84901f9e-5551-455a-a70c-c7e39d9e55ae",
   "metadata": {},
   "source": [
    "E.g. se quiere ajustar un modelo\n",
    "\n",
    "$$ \\hat{z} = \\hat{\\beta_0} + \\hat{\\beta_1} x + \\hat{\\beta_2} y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f473fc-6364-4b15-9bd4-f21a94cae151",
   "metadata": {},
   "source": [
    "Se ajusta el modelo y se decide que la mejor decisión es $\\hat{\\beta_1} = 10000$ y $\\hat{\\beta_2}=50$. Considera limitaciones de problemas reales:\n",
    "- Quizás los parámetros son ajustes de maquinaria que se deben realizar para conseguir el mejor producto posible, y que $10000$ sea imposible de asignar.\n",
    "- Quizás los datos actuales están sesgados y sólo hacen parecer que uno de los factores importa más que el otro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff32fbaa-7965-42c1-9b73-3640414b77f2",
   "metadata": {},
   "source": [
    "Una de las formas en las que se puede mitigar este problema es penalizando a los parámetros del modelo, cambiando la función de costo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc78736-9d8e-4e8b-94f3-6647bdaeb0d1",
   "metadata": {},
   "source": [
    "$$ \\text{RSS}_{L2} = \\sum_{i=1}^n e_i^2  + \\lambda \\sum_{j=1}^p \\hat{\\beta_j}^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d942bf5-fb39-44a0-b612-4ec05ab99b71",
   "metadata": {},
   "source": [
    "El *L2* significa que se está agregando una penalización de segundo orden. Lo que hace esta penalización es que los factores ahora sólo tendrán permitido crecer si hay una reducción al menos proporcional en el error (sacrificamos sesgo, pero reducimos la varianza)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c0cafb-c152-48e4-a345-bb5348eb16c7",
   "metadata": {},
   "source": [
    "Asimismo, existe la penalización *L1*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f2d93-d151-47ed-834f-4a7e91e94286",
   "metadata": {},
   "source": [
    "$$ \\text{RSS}_{L1} = \\sum_{i=1}^n e_i^2  + \\lambda \\sum_{j=1}^p |\\hat{\\beta_j}| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea95f232-25ab-4b4c-99b3-075a18878d95",
   "metadata": {},
   "source": [
    "A las penalizaciones *L2* y *L1* se les conoce también como Ridge y Lasso, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41dfafb-fd1f-475a-a718-dec1e3773326",
   "metadata": {},
   "source": [
    "Para realizar una regresión con penalización de Ridge o de Lasso usamos el objeto `Ridge(alpha=?)` o `Lasso(alpha=?)` en lugar de `LinearRegression()` de `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce36cb41-005e-4cb0-b8ab-92e6ae6c4c19",
   "metadata": {},
   "source": [
    "Utiliza el dataset de publicidad (Advertising.csv) y realiza 3 regresiones múltiples:\n",
    "\n",
    "$$ \\text{sales} = \\beta_0 + \\beta_1 (\\text{TV}) + \\beta_2 (\\text{radio}) + \\beta_3 (\\text{newspaper}) + \\epsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92e4008-ada1-4e82-9756-23fd357821d2",
   "metadata": {},
   "source": [
    "1. Sin penalización\n",
    "2. Con penalización L2\n",
    "3. Con penalización L1\n",
    "\n",
    "Compara los resultados de los parámetros y sus *p-values*, y los $R^2$ resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489b6c52-9025-4ca7-8e96-ca70c294cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f859166-06cf-478e-89d7-e6e5c2cb5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "n = 100\n",
    "x = np.random.randn(n)\n",
    "y = np.random.randn(n)\n",
    "z = 3 + 5*x + 2*y + np.random.randn(n)\n",
    "\n",
    "df = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68128b3f-5be7-4fb1-8998-93ab2ef3d4b7",
   "metadata": {},
   "source": [
    "Aquí genero 100 datos aleatorios para x y y, y creo z como una combinación lineal de ellos más algo de ruido, luego los guardo en un DataFrame para poder trabajar con ellos en los modelos de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53efacc6-e600-4705-b180-3d297324a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"x\", \"y\"]]\n",
    "y_var = df[\"z\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_var, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64001a35-f5ec-4c91-899c-f0d42193e2f2",
   "metadata": {},
   "source": [
    "En este código separa los datos en variables independientes x y dependiente y, luego los divide en conjunto de entrenamiento y prueba (70% y 30%) y finalmente escala las variables para que tengan media 0 y desviación 1, para Ridge y Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69314df7-29fe-4333-88ad-c10043374346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      z   R-squared:                       0.956\n",
      "Model:                            OLS   Adj. R-squared:                  0.954\n",
      "Method:                 Least Squares   F-statistic:                     721.4\n",
      "Date:                Thu, 11 Sep 2025   Prob (F-statistic):           4.78e-46\n",
      "Time:                        10:32:45   Log-Likelihood:                -105.51\n",
      "No. Observations:                  70   AIC:                             217.0\n",
      "Df Residuals:                      67   BIC:                             223.8\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.5957      0.133     19.449      0.000       2.329       2.862\n",
      "x1             4.9897      0.135     36.909      0.000       4.720       5.260\n",
      "x2             1.9922      0.135     14.737      0.000       1.722       2.262\n",
      "==============================================================================\n",
      "Omnibus:                        0.735   Durbin-Watson:                   2.233\n",
      "Prob(Omnibus):                  0.693   Jarque-Bera (JB):                0.551\n",
      "Skew:                          -0.217   Prob(JB):                        0.759\n",
      "Kurtosis:                       2.970   Cond. No.                         1.17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "X_sm = sm.add_constant(X_train_scaled)\n",
    "ols_model = sm.OLS(y_train, X_sm).fit()\n",
    "print(ols_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757b5b7-1d84-41b9-87a4-ad4dd24f392c",
   "metadata": {},
   "source": [
    "En este modelo OLS se observa un R² de 0.956, lo que indica que el ajuste explica muy bien la variabilidad de la variable dependiente. Los coeficientes estimados para x1 y x2 son aproximadamente 5 y 2, respectivamente, con p-values cercanos a 0, lo que confirma que ambas variables son estadísticamente significativas para predecir z.\n",
    "z. Además, el intercepto está alrededor de 2.6, alineándose con la forma en que simulamos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ab397c-3ef9-4ba5-bc29-fbf1132a338e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes Ridge: [4.91310635 1.95216086]\n",
      "R2 Ridge: 0.9475425906607882\n"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Coeficientes Ridge:\", ridge_model.coef_)\n",
    "print(\"R2 Ridge:\", r2_score(y_test, y_pred_ridge))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57231aee-5f1e-4c17-b1af-8f876c4a44fe",
   "metadata": {},
   "source": [
    "En Ridge los coeficientes bajan a 4.91 y 1.95 por la penalización, y el R² sigue alto en 0.9475, mostrando buen ajuste con parámetros más controlados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5315855d-55f3-4916-b781-1bd3d230e6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes Lasso: [4.87072843 1.87329928]\n",
      "R2 Lasso: 0.9482664809025805\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso(alpha=0.1)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = lasso_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Coeficientes Lasso:\", lasso_model.coef_)\n",
    "print(\"R2 Lasso:\", r2_score(y_test, y_pred_lasso))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8efc2-d08f-4a50-89f6-ad67f85c1e72",
   "metadata": {},
   "source": [
    "En Lasso los coeficientes bajan a 4.87 y 1.87 por la penalización L1, y el R² es 0.9483, mostrando buen ajuste con parámetros ligeramente más reducidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b594dbf-5e44-4d45-96f9-cdde8f68395f",
   "metadata": {},
   "source": [
    "En general, los tres modelos muestran un buen ajuste de los datos, con R² altos cerca de 0.95. La penalización en Ridge y Lasso reduce ligeramente los coeficientes, ayudando a controlar posibles valores extremos, pero sin afectar significativamente la capacidad predictiva del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fbd976-84e8-44c2-9c6a-ab6149778215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
